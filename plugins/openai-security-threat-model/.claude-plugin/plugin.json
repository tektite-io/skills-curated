{
  "name": "openai-security-threat-model",
  "version": "1.0.0",
  "description": "Repository-grounded threat modeling that enumerates trust boundaries, assets, attacker capabilities, abuse paths, and mitigations, and writes a concise Markdown threat model. Trigger only when the user explicitly asks to threat model a codebase or path, enumerate threats/abuse paths, or perform AppSec threat modeling. Do not trigger for general architecture summaries, code review, or non-security design work. Originally from OpenAI's curated skills catalog.",
  "author": {
    "name": "OpenAI",
    "url": "https://github.com/openai/skills"
  }
}
